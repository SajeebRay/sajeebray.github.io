---
title: "Attn-CapBN: An Attention-based Bangla Image Captioning using the Bangla View Dataset"
collection: publications
category: manuscripts
permalink: /publication/J5-AttnBanCap
# excerpt: 'Developed a Dual-Head CNN (DH-CNN) for plant leaf classification and disease detection. Achieved 99.71% accuracy in leaf classification and 99.26% in disease identification using the PlantVillage dataset. Enhanced agricultural automation for improved crop management.'
date: 2025-01-01
venue: 'Intelligent Systems with Applications (Under Review; Elsevier-Q1)'
# slidesurl: 'https://www.canva.com/design/DAGgxg-g2Rs/UALlt8twJsyZw7LBEg0R6A/view?utm_content=DAGgxg-g2Rs&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=hcbd6f1c7fb'
paperurl: 'http://dx.doi.org/10.2139/ssrn.5708615'
citation: 'Md Anwar Hossain, Mirza AFM Rashidul Hasan, Sajeeb Kumar Ray, and Naima Islam, Attn-CapBN: An Attention-based Bangla Image Captioning using the Bangla View Dataset. Available at SSRN: https://ssrn.com/abstract=5708615 or http://dx.doi.org/10.2139/ssrn.5708615'
---

Understanding images through natural language descriptions is a fundamental challenge in artificial intelligence, bridging computer vision and natural language processing. While significant progress has been made in English image captioning, resource-scarce languages such as Bangla remain underexplored. To address this gap, this study introduces BanglaView, a large-scale Bangla image captioning dataset inspired by Flickr30k, consisting of 31,783 images paired with 158,915 professionally verified Bangla captions. Each image is annotated with five diverse and fluent descriptions, ensuring both quality and linguistic richness. Building on this resource, we propose Attn-CapBN, an encoderâ€“decoder framework that employs a custom-designed CNN feature extractor and a visual attention mechanism with a GRU decoder to generate contextually coherent Bangla captions. Rigorous training and evaluation were conducted using both BanglaView and the BAN-Cap dataset. Experimental results demonstrate that Attn-CapBN achieves strong performance, with BLEU-1 to BLEU-4 scores of 0.623, 0.487, 0.394, and 0.333 on BanglaView, and 0.620, 0.485, 0.398, and 0.332 on BAN-Cap, respectively. These results surpass existing baselines, highlighting the effectiveness of the proposed CNN-based feature extractor and attention-guided decoding. The contributions of this work include the release of BanglaView as a benchmark dataset and the introduction of Attn-CapBN as a robust architecture for Bangla image captioning, paving the way for further advancements in regional language captioning and multimodal AI research.

<button class = "btn" onclick="window.location.href='https://doi.org/10.1016/j.jafr.2025.101930';">Paper</button>
